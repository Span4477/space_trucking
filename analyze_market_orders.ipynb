{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de23b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read market orders bz2 file into a dataframe\n",
    "with bz2.open(\"data/market-orders-latest.v3.csv.bz2\", \"rt\") as f:\n",
    "    orders_df = pd.read_csv(f)\n",
    "orders_df[\"type_id\"] = orders_df[\"type_id\"].astype(int)\n",
    "orders_df[\"region_id\"] = orders_df[\"region_id\"].astype(int)\n",
    "orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "types_pkl = \"data/types_df.pkl\"\n",
    "with open(types_pkl, \"rb\") as f:\n",
    "    types_df = pickle.load(f)\n",
    "types_df[\"type_id\"] = types_df[\"type_id\"].astype(int)\n",
    "types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1238b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_pkl = \"data/regions_df.pkl\"\n",
    "with open(regions_pkl, \"rb\") as f:\n",
    "    regions_df = pickle.load(f)\n",
    "regions_df[\"region_id\"] = regions_df[\"region_id\"].astype(int)\n",
    "regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_df = pd.read_json(\"data/structures-latest.v2.json\", orient=\"index\")\n",
    "structures_df[\"structure_id\"] = structures_df[\"structure_id\"].astype(int)\n",
    "# structures_df[\"type_id\"] = structures_df[\"type_id\"].astype(int)\n",
    "# structures_df[\"owner_id\"] = structures_df[\"owner_id\"].astype(int)\n",
    "# structures_df = structures_df[\n",
    "#     (structures_df[\"is_market_structure\"] == True)\n",
    "#     & (structures_df[\"is_public_structure\"] == True)\n",
    "# ]\n",
    "structures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84de0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(\"data/stations.csv\")\n",
    "df_stations[\"station_id\"] = df_stations[\"station_id\"].astype(int)\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7606ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_desc = orders_df.merge(types_df, how=\"inner\", on=\"type_id\")\n",
    "orders_with_desc = orders_with_desc.merge(regions_df, how=\"inner\", on=\"region_id\")\n",
    "orders_with_desc = orders_with_desc.merge(df_stations, how=\"inner\", left_on=\"station_id\", right_on=\"station_id\")\n",
    "orders_with_desc[\"station_id\"] = orders_with_desc[\"station_id\"].astype(int)\n",
    "orders_with_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1136f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mapStargates.jsonl from the data folder\n",
    "stargates_df = pd.read_json(\"data/mapStargates.jsonl\", lines=True)\n",
    "stargates_df = stargates_df[['_key', 'destination', 'position', 'solarSystemID', 'typeID']]\n",
    "stargates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mapSolarSystems.jsonl from the data folder\n",
    "solar_systems_df = pd.read_json(\"data/mapSolarSystems.jsonl\", lines=True)\n",
    "solar_systems_df = solar_systems_df[\n",
    "    [\n",
    "        '_key', \n",
    "        'border', \n",
    "        'constellationID', \n",
    "        'hub', \n",
    "        'international',\n",
    "        'luminosity', \n",
    "        'name', \n",
    "        'planetIDs', \n",
    "        'position', \n",
    "        'position2D', \n",
    "        'radius',\n",
    "        'regionID', \n",
    "        'regional', \n",
    "        'securityClass', \n",
    "        'securityStatus', \n",
    "        'starID',\n",
    "        'stargateIDs', \n",
    "        'corridor', \n",
    "        'fringe', \n",
    "        'wormholeClassID', \n",
    "        'visualEffect',\n",
    "        'disallowedAnchorCategories', \n",
    "        'disallowedAnchorGroups', \n",
    "        'factionID'\n",
    "    ]\n",
    "]\n",
    "solar_systems_df[\"name\"] = [x[\"en\"] for x in solar_systems_df[\"name\"]]\n",
    "solar_systems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_name_dict = solar_systems_df[[\"_key\", \"name\"]].set_index(\"_key\")[\"name\"].to_dict()\n",
    "system_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_with_desc[\"system_name\"] = orders_with_desc[\"system_id\"].map(system_name_dict)\n",
    "orders_with_desc[\"system_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8979eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "npc_stations_df = pd.read_json(\"data/npcStations.jsonl\", lines=True)\n",
    "npc_stations_df = npc_stations_df[[\n",
    "    \"_key\",\n",
    "    \"solarSystemID\",\n",
    "]]\n",
    "npc_stations_df[\"system_name\"] = npc_stations_df[\"solarSystemID\"].map(system_name_dict)\n",
    "npc_stations_df = npc_stations_df.rename(columns={\"_key\": \"station_id\", \"solarSystemID\": \"system_id\"})\n",
    "npc_stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af496b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph of the stargates\n",
    "G = nx.DiGraph()\n",
    "for _, row in stargates_df[stargates_df[\"position\"].notna()].iterrows():\n",
    "    G.add_node(system_name_dict[row['solarSystemID']], position=row['position'])\n",
    "    G.add_edge(system_name_dict[row['solarSystemID']], system_name_dict[row['destination'][\"solarSystemID\"]])\n",
    "list(G.edges)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6be18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shortest path between two systems\n",
    "source_system = \"Kino\"\n",
    "target_system = \"Arvasaras\"\n",
    "shortest_path = nx.shortest_path(G, source=source_system, target=target_system)\n",
    "shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buy order aggregation by system\n",
    "orders_with_desc[orders_with_desc[\"is_buy_order\"] == True].groupby(\"system_name\").agg({\n",
    "    \"order_id\": \"count\",\n",
    "    \"price\": [\"mean\", \"median\", \"min\", \"max\"],\n",
    "    \"volume_remain\": \"sum\"\n",
    "}).sort_values(by=(\"order_id\", \"count\"), ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65326f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sell order aggregation by system\n",
    "orders_with_desc[orders_with_desc[\"is_buy_order\"] == False].groupby(\"system_name\").agg({\n",
    "    \"order_id\": \"count\",\n",
    "    \"price\": [\"mean\", \"median\", \"min\", \"max\"],\n",
    "    \"volume_remain\": \"sum\"\n",
    "}).sort_values(by=(\"order_id\", \"count\"), ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21761e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOLUME = 5737\n",
    "cols = [\n",
    "    \"type_id\",\n",
    "    \"type_name\",\n",
    "    \"station_id\",\n",
    "    \"station_name\",\n",
    "    \"system_id\",\n",
    "    \"system_name\",\n",
    "    \"region_id\",\n",
    "    \"region_name\",\n",
    "    \"price\",\n",
    "    \"volume_remain\",    \n",
    "]\n",
    "buy_orders = orders_with_desc[orders_with_desc[\"is_buy_order\"] == True][cols + [\"packaged_volume\"]]\n",
    "sell_orders = orders_with_desc[orders_with_desc[\"is_buy_order\"] == False][cols]\n",
    "buy_sell = buy_orders.merge(\n",
    "    sell_orders,\n",
    "    how=\"inner\",\n",
    "    on=[\"type_id\"],\n",
    "    suffixes=(\"_buy\", \"_sell\"),\n",
    ").dropna()\n",
    "\n",
    "buy_sell = buy_sell[(buy_sell[\"packaged_volume\"] < MAX_VOLUME) & (buy_sell[\"packaged_volume\"] > 0)]\n",
    "buy_sell[\"spread\"] = buy_sell[\"price_buy\"] - buy_sell[\"price_sell\"]\n",
    "buy_sell[\"max_units\"] = MAX_VOLUME / buy_sell[\"packaged_volume\"]\n",
    "buy_sell[\"max_units\"] = buy_sell[\"max_units\"].astype(int)\n",
    "buy_sell[\"max_units\"] = buy_sell[\"volume_remain_buy\"].clip(upper=buy_sell[\"volume_remain_sell\"]).clip(upper=buy_sell[\"max_units\"])\n",
    "# total profit should be spread times the minimum of the 3 volumes, buy sell and max units\n",
    "buy_sell[\"total_profit\"] = buy_sell[\"spread\"] * buy_sell[\"max_units\"] / 1e6\n",
    "buy_sell[\"spread_pct\"] = buy_sell[\"spread\"] / buy_sell[\"price_sell\"] * 100\n",
    "buy_sell = buy_sell[(buy_sell[\"spread\"] > 0) & (buy_sell[\"spread_pct\"] > 10) & (buy_sell[\"total_profit\"] > 25)]\n",
    "buy_sell = buy_sell.sort_values(by=\"spread_pct\", ascending=False)\n",
    "buy_sell.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4af427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_path(row):\n",
    "    if row[\"region_name_sell\"] != \"Pochven\" and row[\"region_name_buy\"] == \"Pochven\":\n",
    "        # Filament into pochven in 1 jump\n",
    "        return 1\n",
    "    try:\n",
    "        if row[\"region_name_sell\"] == \"Pochven\" and row[\"region_name_buy\"] != \"Pochven\":\n",
    "            # Assume we filament out of Pochven near Jita. \n",
    "            path = nx.shortest_path(G, source=\"Jita\", target=row[\"system_name_buy\"])\n",
    "        else:\n",
    "            path = nx.shortest_path(G, source=row[\"system_name_sell\"], target=row[\"system_name_buy\"])\n",
    "        return len(path) - 1\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None\n",
    "buy_sell[\"jumps\"] = buy_sell.apply(_get_path, axis=1)\n",
    "buy_sell[\"profit_per_jump\"] = buy_sell[\"total_profit\"] / buy_sell[\"jumps\"]\n",
    "buy_sell.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ea2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_sell.sort_values(by=\"spread_pct\", ascending=False)[[\n",
    "    \"type_name_buy\",\n",
    "    \"station_name_buy\",\n",
    "    \"station_name_sell\",\n",
    "    \"price_buy\",\n",
    "    \"price_sell\",\n",
    "    \"max_units\",\n",
    "    \"jumps\",\n",
    "    \"total_profit\",\n",
    "    \"spread_pct\",\n",
    "    \"profit_per_jump\",\n",
    "]].head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
