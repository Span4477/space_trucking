{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94052a6b",
   "metadata": {},
   "source": [
    "This file gets data from the internet and prepares it in a form that is convenient for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tarfile\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "import bz2\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_YEAR = 2026\n",
    "BASE_YEAR_URL = \"https://data.everef.net/market-history/{year}/\"\n",
    "OUT_DIR = Path(\"data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UA = {\"User-Agent\": \"everef-market-history-downloader (python requests)\"}\n",
    "\n",
    "# matches: market-history-YYYY-MM-DD.csv.bz2\n",
    "FILE_RE = re.compile(r\"market-history-\\d{4}-\\d{2}-\\d{2}\\.csv\\.bz2$\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(year_url: str) -> list[str]:\n",
    "    \"\"\"Return absolute URLs of all matching .csv.bz2 files listed on the year page.\"\"\"\n",
    "    r = requests.get(year_url, headers=UA, timeout=60)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    # Simple href extraction (works for typical directory listings)\n",
    "    hrefs = re.findall(r'href=\"([^\"]+)\"', r.text)\n",
    "\n",
    "    files = []\n",
    "    for href in hrefs:\n",
    "        name = href.split(\"/\")[-1]\n",
    "        if FILE_RE.search(name):\n",
    "            files.append(urljoin(year_url, href))\n",
    "\n",
    "    # de-dup + stable order\n",
    "    return sorted(set(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, out_dir: Path, force=False) -> Path:\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    out_path = out_dir / filename\n",
    "\n",
    "    if out_path.exists() and out_path.stat().st_size > 0 and not force:\n",
    "        print(f\"SKIP  {filename}\")\n",
    "        return out_path\n",
    "\n",
    "    print(f\"GET   {filename}\")\n",
    "    with requests.get(url, headers=UA, stream=True, timeout=120) as r:\n",
    "        r.raise_for_status()\n",
    "        tmp_path = out_path.with_suffix(out_path.suffix + \".part\")\n",
    "        with open(tmp_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        tmp_path.replace(out_path)\n",
    "    time.sleep(0.5)  # be nice to the server\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82708d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in range(START_YEAR, datetime.now().year + 1):\n",
    "    year_url = BASE_YEAR_URL.format(year=year)\n",
    "    urls = list_files(year_url)\n",
    "    for u in urls:\n",
    "        try:\n",
    "            download(u, OUT_DIR)\n",
    "        except Exception as e:\n",
    "            print(f\"FAIL  {u}  ({e})\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all bz2 files into a single dataframe\n",
    "dfs = []\n",
    "for file_path in OUT_DIR.glob(\"market-history-*.csv.bz2\"):\n",
    "    with bz2.open(file_path, \"rt\") as f:\n",
    "        temp_df = pd.read_csv(f)\n",
    "        # filter for The Forge\n",
    "        temp_df = temp_df[temp_df[\"region_id\"] == 10000002]\n",
    "        temp_df = temp_df[[\n",
    "            \"average\",\n",
    "            \"date\",\n",
    "            \"highest\",\n",
    "            \"lowest\",\n",
    "            \"order_count\",\n",
    "            \"volume\",\n",
    "            \"type_id\",\n",
    "        ]]\n",
    "        dfs.append(temp_df)\n",
    "\n",
    "df: pd.DataFrame = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tar_path = Path(\"data/reference-data-latest.tar.xz\")\n",
    "with tarfile.open(tar_path, \"r:xz\") as tar:\n",
    "\n",
    "    # print out all the file names\n",
    "    for member in tar.getmembers():\n",
    "        print(f\"Extracting {member.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc9278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tarfile.open(tar_path, \"r:xz\") as tar:\n",
    "    market_groups = tar.extractfile(\"types.json\")\n",
    "    market_groups_data = yaml.safe_load(market_groups)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_groups_df = pd.DataFrame([\n",
    "    {\n",
    "        \"type_id\": k, \n",
    "        \"type_name\": i[\"name\"][\"en\"],\n",
    "        \"packaged_volume\": i[\"packaged_volume\"] if \"packaged_volume\" in i else None\n",
    "        }\n",
    "    for k, i in market_groups_data.items()\n",
    "])\n",
    "market_groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11127821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(OUT_DIR / \"types_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(market_groups_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded from:\n",
    "# https://data.everef.net/reference-data/\n",
    "tar_path = Path(\"data/reference-data-latest.tar.xz\")\n",
    "def extract_labels():\n",
    "    # unzip only once\n",
    "    with tarfile.open(tar_path, \"r:xz\") as tar:\n",
    "\n",
    "\n",
    "        types_file = tar.extractfile(\"types.json\")\n",
    "        regions_file = tar.extractfile(\"regions.json\")\n",
    "        # stations_file = tar.extractfile(\"universe/stations.json\")\n",
    "\n",
    "        types_data = yaml.safe_load(types_file)\n",
    "        regions_data = yaml.safe_load(regions_file)\n",
    "        # stations_data = yaml.safe_load(stations_file)\n",
    "    types_df = pd.DataFrame([\n",
    "        {\n",
    "            \"type_id\": k, \n",
    "            \"type_name\": i[\"name\"][\"en\"],\n",
    "            \"packaged_volume\": i[\"packaged_volume\"]\n",
    "        }\n",
    "        for k, i in types_data.items()\n",
    "    ])\n",
    "    regions_df = pd.DataFrame([\n",
    "        {\"region_id\": k, \"region_name\": i[\"name\"][\"en\"]}\n",
    "        for k, i in regions_data.items()\n",
    "    ])\n",
    "    # stations_df = pd.DataFrame([\n",
    "    #     {\"station_id\": k, \"station_name\": i[\"name\"][\"en\"], \"region_id\": i[\"region_id\"]}\n",
    "    #     for k, i in stations_data.items()\n",
    "    # ])\n",
    "    # save pickles\n",
    "    with open(OUT_DIR / \"types_df.pkl\", \"wb\") as f:\n",
    "        pickle.dump(types_df, f)\n",
    "    with open(OUT_DIR / \"regions_df.pkl\", \"wb\") as f:\n",
    "        pickle.dump(regions_df, f)\n",
    "    # with open(OUT_DIR / \"stations_df.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(stations_df, f)\n",
    "    return types_df, regions_df\n",
    "\n",
    "def get_labels():\n",
    "    types_pkl = OUT_DIR / \"types_df.pkl\"\n",
    "    regions_pkl = OUT_DIR / \"regions_df.pkl\"\n",
    "    # stations_pkl = OUT_DIR / \"stations_df.pkl\"\n",
    "    if types_pkl.exists() and regions_pkl.exists():\n",
    "        with open(types_pkl, \"rb\") as f:\n",
    "            types_df = pickle.load(f)\n",
    "        with open(regions_pkl, \"rb\") as f:\n",
    "            regions_df = pickle.load(f)\n",
    "        # with open(stations_pkl, \"rb\") as f:\n",
    "        #     stations_df = pickle.load(f)\n",
    "    else:\n",
    "        types_df, regions_df = extract_labels()\n",
    "    return types_df, regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df, regions_df = get_labels()\n",
    "regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type_id\"] = df[\"type_id\"].astype(int)\n",
    "types_df[\"type_id\"] = types_df[\"type_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(types_df, on=\"type_id\", how=\"left\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the forge dataframe\n",
    "with open(OUT_DIR / \"forge_market_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8830544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get market orders\n",
    "url = \"https://data.everef.net/market-orders/market-orders-latest.v3.csv.bz2\"\n",
    "out_path = download(url, OUT_DIR, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d45204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read market orders bz2 file into a dataframe\n",
    "with bz2.open(out_path, \"rt\") as f:\n",
    "    orders_df = pd.read_csv(f)\n",
    "orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.everef.net/structures/structures-latest.json\"\n",
    "out_path = download(url, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read structures json file\n",
    "structures1_df = pd.read_json(out_path)\n",
    "structures1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.everef.net/industry-facilities/industry-facilities-latest.json\"\n",
    "out_path = download(url, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58400fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read structures json file\n",
    "indy_df = pd.read_json(out_path)\n",
    "indy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.everef.net/structures/structures-latest.v2.json\"\n",
    "out_path = download(url, OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read structures json file\n",
    "structures_df = pd.read_json(out_path, orient=\"index\")\n",
    "structures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_df[structures_df[\"name\"].notna()][structures_df[\"name\"].astype(str).str.contains(\"Caldari\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740141fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_df[\n",
    "    (structures_df[\"is_market_structure\"] == True)\n",
    "    & (structures_df[\"is_public_structure\"] == True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef61af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(\"data/stations.csv\")\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://developers.eveonline.com/static-data/tranquility/eve-online-static-data-3171578-jsonl.zip\"\n",
    "out_path = download(url, OUT_DIR)\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(out_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(OUT_DIR)\n",
    "extracted_files = list(OUT_DIR.glob(\"*.jsonl\"))\n",
    "extracted_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
